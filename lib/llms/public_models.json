{
    "anthropic": {
        "executor": "AnthropicExecutor",
        "connection": {
            "api_key_env_var": "ANTHROPIC_API_KEY"
        },
        "models": {
            "claude-opus-4-20250514": {
                "aliases": ["claude-opus-4-0"],
                "latest": true,
                "input": 15.00,
                "output": 75.00,
                "cache_write_5min": 18.75,
                "cache_write_1hr": 30.00,
                "cache_read": 1.50,
                "context_window": 200000,
                "max_output": 32000,
                "max_output_thinking": 32000
            },
            "claude-sonnet-4-20250514": {
                "aliases": ["claude-sonnet-4-0"],
                "latest": true,
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 64000,
                "max_output_thinking": 64000
            },
            "claude-3-7-sonnet-20250219": {
                "aliases": ["claude-3-7-sonnet-latest"],
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192,
                "max_output_thinking": 64000,
                "_note": "Include the beta header output-128k-2025-02-19 in your API request to increase the maximum output token length to 128k tokens for Claude 3.7 Sonnet."
            },
            "claude-3-5-sonnet-20241022": {
                "aliases": ["claude-3-5-sonnet-latest"],
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-5-sonnet-20240620": {
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-5-haiku-20241022": {
                "aliases": ["claude-3-5-haiku-latest"],
                "latest": true,
                "input": 0.8,
                "output": 4.00,
                "cache_write_5min": 1.00,
                "cache_write_1hr": 1.60,
                "cache_read": 0.08,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-opus-20240229": {
                "input": 15.00,
                "output": 75.00,
                "cache_write_5min": 18.75,
                "cache_write_1hr": 30.00,
                "cache_read": 1.50,
                "context_window": 200000,
                "max_output": 4096
            },
            "claude-3-haiku-20240307": {
                "input": 0.25,
                "output": 1.25,
                "cache_write_5min": 0.30,
                "cache_write_1hr": 0.50,
                "cache_read": 0.03,
                "context_window": 200000,
                "max_output": 4096
            }
        },
        "tools": true,
        "enabled": true
    },

    "google": {
        "executor": "GoogleGeminiExecutor",
        "connection": {
            "api_key_env_var": "GOOGLE_GEMINI_API_KEY"
        },
        "models": {
            "gemini-2.5-pro": {
                "latest": true,
                "input": 1.25,
                "output": 10.00,
                "cache_write_1mt/hr": 4.50,
                "cache_read": 0.31,
                "context_window": 1048576,
                "max_output": 65536
            },
            "gemini-2.5-flash": {
                "latest": true,
                "input": 0.30,
                "output": 1.00,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.075,
                "context_window": 1048576,
                "context_window": 1048576,
                "max_output": 65536
            },
            "gemini-2.5-flash-lite-preview-06-17": {
                "latest": true,
                "input": 0.10,
                "output": 0.40,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.025,
                "context_window": 1000000,
                "max_output": 64000
            },
            "gemini-2.0-flash": {
                "input": 0.10,
                "output": 0.40,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.025,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-2.0-flash-lite": {
                "input": 0.075,
                "output": 0.30,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-1.5-pro": {
                "input": 1.25,
                "output": 5.00,
                "cache_write_1mt/hr": 4.50,
                "cache_read": 0.3125,
                "context_window": 2097152,
                "max_output": 8192
            },
            "gemini-1.5-flash": {
                "input": 0.075,
                "output": 0.30,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.0185,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-1.5-flash-8b": {
                "input": 0.0375,
                "output": 0.075,
                "cache_write_1mt/hr": 0.25,
                "cache_read": 0.01,
                "context_window": 1048576,
                "max_output": 8192
            }
        },
        "tools": true,
        "enabled": true
    },

    "xai": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "XAI_API_KEY",
            "base_url": "https://api.x.ai/v1"
        },
        "models": {
            "grok-4-0709": {
                "latest": true,
                "input": 3.00,
                "output": 15.00,
                "context_window": 256000
            },
            "grok-3": {
                "input": 3.00,
                "output": 15.00,
                "context_window": 131072
            },
            "grok-3-mini": {
                "latest": true,
                "input": 0.30,
                "output": 0.50,
                "context_window": 131072
            },
            "grok-3-fast": {
                "input": 5.00,
                "output": 25.00,
                "context_window": 131072
            },
            "grok-3-mini-fast": {
                "latest": true,
                "input": 0.60,
                "output": 4.00,
                "context_window": 131072
            },
            "grok-2-1212": {
                "input": 2.00,
                "output": 10.00,
                "context_window": 131072
            },
            "grok-2-vision-1212": {
                "input": 2.00,
                "output": 10.00,
                "context_window": 32768
            }
        },
        "tools": true,
        "enabled": true
    },

    "cerebras": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "CEREBRAS_API_KEY",
            "base_url": "https://api.cerebras.ai/v1",
            "exclude_params": ["max_tokens"]
        },
        "models": {
            "llama-4-scout-17b-16e-instruct": {
                "input": 0.65,
                "output": 0.85,
                "context_window": 8192,
                "tools": true
            },
            "llama3.1-8b": {
                "input": 0.10,
                "output": 0.10,
                "context_window": 8192,
                "tools": true
            },
            "llama3.3-70b": {
                "input": 0.85,
                "output": 1.20,
                "context_window": 8192,
                "tools": true
            },
            "qwen-3-32b": {
                "input": 0.40,
                "output": 0.80,
                "context_window": 64000,
                "tools": true,
                "enabled": false
            },
            "qwen-3-235b-a22b": {
                "input": 0.60,
                "output": 1.20,
                "context_window": 41000,
                "tools": true,
                "enabled": false
            }
        },
        "enabled": true
    },

    "hyperbolic": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "HYPERBOLIC_API_KEY",
            "base_url": "https://api.hyperbolic.xyz/v1"
        },
        "models": {
            "moonshotai/Kimi-K2-Instruct": {
                "input": 2.00,
                "output": 2.00,
                "context_window": 131069
            },
            "deepseek-ai/DeepSeek-R1-0528": {
                "input": 3.00,
                "output": 3.00,
                "context_window": 163840
            },
            "Qwen/Qwen3-235B-A22B": {
                "input": 0.40,
                "output": 0.40,
                "context_window": 40960
            },
            "deepseek-ai/DeepSeek-V3-0324": {
                "input": 1.25,
                "output": 1.25,
                "context_window": 131069
            },
            "Qwen/QwQ-32B": {
                "input": 0.40,
                "output": 0.40,
                "context_window": 131069
            },
            "meta-llama/Llama-3.3-70B-Instruct": {
                "input": 0.40,
                "output": 0.40,
                "context_window": 131069
            },
            "Qwen/Qwen2.5-Coder-32B-Instruct": {
                "input": 0.2,
                "output": 0.2,
                "context_window": 131072
            }
        },
        "enabled": true,
        "tools": false
    },

    "groq": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "GROQ_API_KEY",
            "base_url": "https://api.groq.com/openai/v1"
        },
        "models": {
            "llama-3.3-70b-versatile": {
                "input": 0.59,
                "output": 0.79,
                "context_window": 131072,
                "max_tokens": 32768,
                "tools": true
            },
            "llama-3.1-8b-instant": {
                "input": 0.05,
                "output": 0.08,
                "context_window": 131072,
                "max_tokens": 131072,
                "tools": true
            }
        },
        "enabled": true
    },

    "together": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "TOGETHER_API_KEY",
            "base_url": "https://api.together.xyz/v1",
            "exclude_params": ["max_completion_tokens"]
        },
        "models": {
            "moonshotai/Kimi-K2-Instruct": {
                "input": 1.00,
                "output": 3.00,
                "context_window": 128000,
                "quantization": "FP8",
                "tools": true
            },
            "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
                "input": 0.27,
                "output": 0.85,
                "context_window": 1048576,
                "quantization": "FP8",
                "tools": true
            },
            "meta-llama/Llama-4-Scout-17B-16E-Instruct": {
                "input": 0.18,
                "output": 0.59,
                "context_window": 1048576,
                "tools": true
            },
            "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
                "input": 0.88,
                "output": 0.88,
                "context_window": 131072,
                "quantization": "FP8",
                "tools": true
            },
            "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
                "input": 0.06,
                "output": 0.06,
                "context_window": 131072,
                "tools": true
            },
            "Qwen/Qwen3-235B-A22B-fp8-tput": {
                "input": 0.20,
                "output": 0.60,
                "context_window": 40960,
                "quantization": "FP8",
                "tools": true
            },
            "deepseek-ai/DeepSeek-V3": {
                "input": 1.25,
                "output": 1.25,
	        "context_window": 163839,
                "quantization": "FP8",
                "tools": true
            }
        },
        "enabled": true
    },

    "fireworks": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "FIREWORKS_API_KEY",
            "base_url": "https://api.fireworks.ai/inference/v1",
            "exclude_params": ["max_tokens"]
        },
        "models": {
            "accounts/fireworks/models/deepseek-r1-0528": {
                "input": 3.00,
                "output": 8.00,
                "context_window": 160000,
                "tools": false
            },
            "accounts/fireworks/models/qwen3-235b-a22b": {
                "input": 0.22,
                "output": 0.88,
                "context_window": 128000,
                "tools": true
            },
            "accounts/fireworks/models/qwen3-30b-a3b": {
                "input": 0.15,
                "output": 0.60,
                "context_window": 128000,
                "tools": true
            },
            "accounts/fireworks/models/llama4-maverick-instruct-basic": {
                "input": 0.22,
                "output": 0.88,
                "context_window": 1000000,
                "tools": true
            },
            "accounts/fireworks/models/llama4-scout-instruct-basic": {
                "input": 0.15,
                "output": 0.60,
                "context_window": 10000000,
                "tools": true
            },
            "accounts/fireworks/models/deepseek-v3-0324": {
                "input": 0.90,
                "output": 0.90,
                "context_window": 160000,
                "tools": true
            },
            "accounts/fireworks/models/kimi-k2-instruct" : {
                "input": 1.00,
                "output": 3.00,
                "context_window": 128000,
                "tools": true
            }
        },
        "enabled": true
    },

    "deepinfra": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "DEEPINFRA_API_KEY",
            "base_url": "https://api.deepinfra.com/v1/openai"
        },
        "models": {
            "moonshotai/Kimi-K2-Instruct": {
                "input": 0.55,
                "output": 2.20,
                "context_window": 120000,
                "quantization": "FP4",
                "tools": true
            }
        },
        "enabled": false
    },

    "novita": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "NOVITA_API_KEY",
            "base_url": "https://api.novita.ai/v3/openai"
        },
        "models": {
            "moonshotai/kimi-k2-instruct": {
                "input": 0.57,
                "output": 2.30,
                "context_window": 131072,
                "tools": true
            },
            "deepseek/deepseek-v3-0324": {
                "input": 0.28,
                "output": 1.14,
                "context_window": 163840,
                "tools": true
            }
        },
        "enabled": false
    }
}
