{
    "anthropic": {
        "executor": "AnthropicExecutor",
        "connection": {
            "api_key_env_var": "ANTHROPIC_API_KEY"
        },
        "models": {
            "claude-opus-4-20250514": {
                "aliases": ["claude-opus-4-0"],
                "latest": true,
                "input": 15.00,
                "output": 75.00,
                "cache_write_5min": 18.75,
                "cache_write_1hr": 30.00,
                "cache_read": 1.50,
                "context_window": 200000,
                "max_output": 32000,
                "max_output_thinking": 32000
            },
            "claude-sonnet-4-20250514": {
                "aliases": ["claude-sonnet-4-0"],
                "latest": true,
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 64000,
                "max_output_thinking": 64000
            },
            "claude-3-7-sonnet-20250219": {
                "aliases": ["claude-3-7-sonnet-latest"],
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192,
                "max_output_thinking": 64000,
                "_note": "Include the beta header output-128k-2025-02-19 in your API request to increase the maximum output token length to 128k tokens for Claude 3.7 Sonnet."
            },
            "claude-3-5-sonnet-20241022": {
                "aliases": ["claude-3-5-sonnet-latest"],
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-5-sonnet-20240620": {
                "input": 3.00,
                "output": 15.00,
                "cache_write_5min": 3.75,
                "cache_write_1hr": 6.00,
                "cache_read": 0.30,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-5-haiku-20241022": {
                "aliases": ["claude-3-5-haiku-latest"],
                "latest": true,
                "input": 0.8,
                "output": 4.00,
                "cache_write_5min": 1.00,
                "cache_write_5min": 1.60,
                "cache_read": 0.08,
                "context_window": 200000,
                "max_output": 8192
            },
            "claude-3-opus-20240229": {
                "input": 15.00,
                "output": 75.00,
                "cache_write_5min": 18.75,
                "cache_write_1hr": 30.00,
                "cache_read": 1.50,
                "context_window": 200000,
                "max_output": 4096
            },
            "claude-3-haiku-20240307": {
                "input": 0.25,
                "output": 1.25,
                "cache_write_5min": 0.30,
                "cache_write_1hr": 0.50,
                "cache_read": 0.03,
                "context_window": 200000,
                "max_output": 4096
            }
        },
        "enabled": true
    },

    "google": {
        "executor": "GoogleGeminiExecutor",
        "connection": {
            "api_key_env_var": "GOOGLE_GEMINI_API_KEY"
        },
        "models": {
            "gemini-2.5-pro": {
                "latest": true,
                "input": 1.25,
                "output": 10.00,
                "cache_write_1mt/hr": 4.50,
                "cache_read": 0.31,
                "context_window": 1048576,
                "max_output": 65536
            },
            "gemini-2.5-flash": {
                "latest": true,
                "input": 0.30,
                "output": 1.00,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.075,
                "context_window": 1048576,
                "context_window": 1048576,
                "max_output": 65536
            },
            "gemini-2.5-flash-lite-preview-06-17": {
                "latest": true,
                "input": 0.10,
                "output": 0.40,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.025,
                "context_window": 1000000,
                "max_output": 64000
            },
            "gemini-2.0-flash": {
                "input": 0.10,
                "output": 0.40,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.025,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-2.0-flash-lite": {
                "input": 0.075,
                "output": 0.30,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-1.5-pro": {
                "input": 1.25,
                "output": 5.00,
                "cache_write_1mt/hr": 4.50,
                "cache_read": 0.3125,
                "context_window": 2097152,
                "max_output": 8192
            },
            "gemini-1.5-flash": {
                "input": 0.075,
                "output": 0.30,
                "cache_write_1mt/hr": 1.00,
                "cache_read": 0.0185,
                "context_window": 1048576,
                "max_output": 8192
            },
            "gemini-1.5-flash-8b": {
                "input": 0.0375,
                "output": 0.075,
                "cache_write_1mt/hr": 0.25,
                "cache_read": 0.01,
                "context_window": 1048576,
                "max_output": 8192
            }
        },
        "enabled": true
    },

    "xai": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "XAI_API_KEY",
            "base_url": "https://api.x.ai/v1"
        },
        "models": {
            "grok-4-0709": {
                "latest": true,
                "input": 3.00,
                "output": 15.00,
                "context_window": 256000
            },
            "grok-3": {
                "input": 3.00,
                "output": 15.00,
                "context_window": 131072
            },
            "grok-3-mini": {
                "latest": true,
                "input": 0.30,
                "output": 0.50,
                "context_window": 131072
            },
            "grok-3-fast": {
                "input": 5.00,
                "output": 25.00,
                "context_window": 131072
            },
            "grok-3-mini-fast": {
                "latest": true,
                "input": 0.60,
                "output": 4.00,
                "context_window": 131072
            },
            "grok-2-1212": {
                "input": 2.00,
                "output": 10.00,
                "context_window": 131072
            },
            "grok-2-vision-1212": {
                "input": 2.00,
                "output": 10.00,
                "context_window": 32768
            }
        },
        "enabled": true
    },

    "cerebras": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "CEREBRAS_API_KEY",
            "base_url": "https://api.cerebras.ai/v1",
            "exclude_params": ["max_tokens"]
        },
        "models": {
            "llama3.1-8b": {
                "input": 0.00,
                "output": 0.00,
                "context_window": 8192,
                "tools": true
            },
            "llama3.3-70b": {
                "input": 0.00,
                "output": 0.00,
                "context_window": 8192,
                "tools": true
            }
        },
        "enabled": true,
        "_todo": "check pricing, check max output, check availailability of usage data"
    },

    "hyperbolic": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "HYPERBOLIC_API_KEY",
            "base_url": "https://api.hyperbolic.xyz/v1"
        },
        "models": {
            "Qwen/Qwen2.5-Coder-32B-Instruct": {
                "input": 0.2,
                "output": 0.2,
                "_checked": true
            },
            "deepseek-ai/DeepSeek-V3": {
                "input": 0.25,
                "output": 0.25,
                "context_window": 131000,
                "_checked": true,
                "quantization": "fp8"
            },
            "Qwen/Qwen2-VL-7B-Instruct": {
                "quantization": "bf16",
                "input": 0.1,
                "output": 0.1,
                "_images": true,
                "_checked": true
            },
            "Qwen/Qwen2-VL-72B-Instruct": {
                "quantization": "bf16",
                "input": 0.4,
                "output": 0.4,
                "_images": true,
                "_checked": true
            }
        },
        "enabled": true,
        "tools": false,
        "_todo": "check pricing; double check no tool support"
    },

    "groq": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "GROQ_API_KEY",
            "base_url": "https://api.groq.com/openai/v1"
        },
        "models": {
            "llama-3.3-70b-specdec": {
                "input": 0.59,
                "output": 0.99,
                "context_window": 8000,
                "tools": false,
                "_checked": true
            },
            "llama-3.3-70b-versatile": {
                "input": 0.59,
                "output": 0.79,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "llama-3.1-8b-instant": {
                "input": 0.05,
                "output": 0.08,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "llama-3.2-90b-vision-preview": {
                "input": 0.90,
                "output": 0.90,
                "_checked": false,
                "context_window": 8192,
                "tools": false,
                "_images": true,
                "_checked": true
            },
            "deepseek-r1-distill-llama-70b": {
                "input": 0.75,
                "output": 0.99,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "deepseek-r1-distill-qwen-32b": {
                "input": 0.69,
                "output": 0.69,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "deepseek-r1-distill-qwen-32b": {
                "tools": true,
                "_checked": true
            },
            "qwen-qwq-32b": {
                "input": 0.29,
                "output": 0.39,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "qwen-2.5-coder-32b": {
                "input": 0.79,
                "output": 0.79,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "qwen-2.5-32b": {
                "input": 0.79,
                "output": 0.79,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            }
        },
        "_todo": "check pricing",
        "enabled": true
    },

    "together": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "TOGETHER_API_KEY",
            "base_url": "https://api.together.xyz/v1",
            "exclude_params": ["max_completion_tokens"]
        },
        "models": {
            "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
                "input": 0.88,
                "output": 0.88,
                "tools": true
            },
            "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
                "input": 0.88,
                "output": 0.88,
                "tools": true
            },
            "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
                "input": 3.50,
                "output": 3.50,
                "tools": true
            },
            "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
                "input": 0.18,
                "output": 0.18,
                "tools": true
            },
            "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
                "input": 0.06,
                "output": 0.06,
                "tools": false
            },
            "deepseek-ai/DeepSeek-V3": {
	        "context_window": 131072,
                "quantization": "FP8",
                "input": 1.25,
                "output": 1.25,
                "tools": true,
                "_checked": true
            },
            "deepseek-ai/DeepSeek-R1": {
	        "context_window": 163840,
	        "quantization": "FP8",
                "input": 7.00,
                "output": 7.00,
                "tools": false,
                "_checked": true
            },
            "meta-llama/Llama-Vision-Free": {
	        "context_window": 131072,
                "input": 0.00,
                "output": 0.00,
                "_images": true,
                "_checked": true
            },
            "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
	        "context_window": 131072,
                "input": 0.18,
                "output": 0.18,
                "_images": true,
                "_checked": false
            },
            "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
	        "context_window": 131072,
                "input": 0.88,
                "output": 0.88,
                "_images": true,
                "_checked": false
            },
            "Qwen/Qwen2.5-72B-Instruct-Turbo": {
	        "context_window": 32768,
                "input": 1.20,
                "output": 1.20,
                "tools": true,
                "_checked": false
            },
            "Qwen/Qwen2-VL-72B-Instruct": {
	        "context_window": 32768,
                "input": 1.20,
                "output": 1.20,
                "tools": false,
                "_images": true,
                "_checked": false
            }

        },
        "_note": "tool calling fails",
        "_todo": "all from https://docs.together.ai/docs/serverless-models",
        "enabled": true
    },

    "fireworks": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "FIREWORKS_API_KEY",
            "base_url": "https://api.fireworks.ai/inference/v1",
            "exclude_params": ["max_tokens"]
        },
        "models": {
            "accounts/fireworks/models/deepseek-r1": {
                "input": 3.00,
                "output": 8.00,
                "context_window": 160000,
                "tools": false,
                "_checked": true
            },
            "accounts/fireworks/models/deepseek-v3": {
                "input": 0.75,
                "output": 3.00,
                "context_window": 128000,
                "tools": false,
                "_note": "claimed that tools are enabled: https://fireworks.ai/blog/function-calling-deepseekv3",
                "_checked": false
            },
            "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
                "input": 0.90,
                "output": 0.90,
                "_images": true
            },
            "accounts/fireworks/models/llama-v3p1-405b-instruct": {
                "input": 3.00,
                "output": 3.00,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "accounts/fireworks/models/llama-v3p1-70b-instruct": {
                "input": 0.90,
                "output": 0.90,
                "context_window": 128000,
                "tools": true,
                "_checked": true
            },
            "accounts/fireworks/models/qwen2p5-72b-instruct": {
                "input": 0.90,
                "output": 0.90,
                "context_window": 32000,
                "tools": true,
                "_checked": true
            }
        },
        "enabled": true
    },

    "deepinfra": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "DEEPINFRA_API_KEY",
            "base_url": "https://api.deepinfra.com/v1/openai"
        },
        "models": {
            "deepseek-ai/DeepSeek-V3": {
                "input": 0.49,
                "output": 0.89,
                "context_window": 65536,
                "quantization": "fp8",
                "tools": true,
                "_checked": true
            },
            "deepseek-ai/DeepSeek-R1": {
                "input": 0.75,
                "output": 2.40,
                "context_window": 65536,
                "quantization": "fp8",
                "tools": true,
                "_checked": true
            },
            "deepseek-ai/DeepSeek-R1-Turbo": {
                "input": 2.00,
                "output": 6.00,
                "context_window": 32768,
                "quantization": "fp4",
                "tools": true,
                "_checked": true
            },
            "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
                "input": 0.23,
                "output": 0.69,
                "context_window": 131072,
                "quantization": "bfloat16",
                "tools": false,
                "_checked": true
            },
            "meta-llama/Llama-3.3-70B-Instruct": {
                "input": 0.23,
                "output": 0.40,
                "context_window": 131072,
                "tools": true,
                "quantization": "bfloat16",
                "_checked": true
            },
            "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
                "input": 0.12,
                "output": 0.30,
                "context_window": 131072,
                "tools": true,
                "quantization": "fp8",
                "_checked": true
            },
            "meta-llama/Llama-3.2-90B-Vision-Instruct": {
                "input": 0.35,
                "output": 0.40,
                "context_window": 32768,
                "quantization": "bf16",
                "_checked": true
            },
            "Qwen/QwQ-32B": {
                "input": 0.12,
                "output": 0.18,
                "context_window": 131072,
                "quantization": "bf16",
                "tools": true,
                "_note": "actually might just be json structured output not full tools",
                "_checked": true
            }

        },
        "_note": "tool use erroring, no tool calls when stremaing, rejects tool result reposne when non streaming",
        "enabled": true
    },

    "novita": {
        "executor": "OpenAICompatibleExecutor",
        "connection": {
            "api_key_env_var": "NOVITA_API_KEY",
            "base_url": "https://api.novita.ai/v3/openai"
        },
        "models": {
            "deepseek/deepseek_v3": {
                "input": 0.89,
                "output": 0.89,
                "context_window": 64000,
                "tools": false,
                "json": true,
                "_note": "docs claim json structured output support, and that you must instruct the model to do so",
                "_checked": false
            },
            "deepseek/deepseek-v3-turbo": {
                "input": 0.40,
                "output": 1.30,
                "context_window": 64000,
                "tools": false,
                "json": true,
                "_note": "docs claim json structured output support, and that you must instruct the model to do so",
                "_checked": false
            }
        },
        "_todo": "more models here: https://novita.ai/models",
        "enabled": true
    },

    "hugging_face": {
        "executor": "HuggingFaceExecutor",
        "connection": {
            "api_key_env_var": "HUGGING_FACE_INFERENCE_API_KEY"
        },
        "models": {
            "mistralai/Mistral-7B-Instruct-v0.3": { "input": 0.00, "output": 0.00 },
            "Qwen/Qwen2.5-72B-Instruct": { "input": 0.00, "output": 0.00 },
            "Qwen/QwQ-32B-Preview": { "input": 0.00, "output": 0.00 },
            "google/gemma-2-9b-it": { "input": 0.00, "output": 0.00 },
            "microsoft/Phi-3.5-mini-instruct": { "input": 0.00, "output": 0.00 }
        },
        "enabled": false
    }
}
