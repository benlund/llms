#!/usr/bin/env ruby

require_relative '../lib/llms/executors'
require_relative '../lib/llms/conversation'
require 'optparse'
require 'tempfile'
require 'open-uri'
require 'base64'

$image_data = Base64.strict_encode64(URI.open('https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png').read)

def test_model(model_name, stream: false, usage: false)
  begin
    executor = LLMs::Executors.instance(model_name: model_name, max_tokens: 100)

    cm = LLMs::Conversation.new
    ##@@ TODO not working for Google Gemini models @@
    ##@@ TODO not supported for Groq vision models @@
    cm.set_system_message("Always reply in Latin")
    cm.add_user_message([{
        text: 'What is in this picture?',
        image: $image_data
    }])

    if stream
      print "#{model_name}: "
      executor.execute_conversation(cm) do |chunk|
        print chunk
      end
      puts
    else
      response_message = executor.execute_conversation(cm)
      puts "#{model_name}: #{response_message&.text}"
    end

    if executor.last_error
      puts 'ERROR: ' + executor.last_error.inspect
    end

    if usage
      puts executor.last_usage_data.inspect
    end
  rescue => e
    puts "#{model_name}: ERROR - #{e.message}"
    puts e.backtrace
  end
end

def main
  options = {}
  OptionParser.new do |opts|
    opts.on("--stream", "Stream the output") do |v|
      options[:stream] = v
    end
    opts.on("--usage", "Show usage") do |v|
      options[:usage] = v
    end
  end.parse!

  models = LLMs::Models.list_model_names
  if ARGV[0]
    models = models.select { |name| name.include?(ARGV[0]) }
  end

  models.each do |model_name|
    test_model(model_name, stream: options[:stream], usage: options[:usage])
    puts "-" * 80
  end
end

main
