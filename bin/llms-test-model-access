#!/usr/bin/env ruby

require_relative '../lib/llms/executors'
require 'optparse'

def test_model(model_name, stream: false, usage: false)
  begin
    executor = LLMs::Executors.instance(model_name: model_name, max_tokens: 10, system_prompt: "Always reply with numbers as WORDS not digits.")

    if stream
      print "#{model_name}: "
      response = executor.execute_prompt("2+2=") do |chunk|
        print chunk
      end
      puts
    else
      response = executor.execute_prompt("2+2=")
      puts "#{model_name}: #{response}"
    end

    if executor.last_error
      puts 'ERROR: ' + executor.last_error.inspect
    end

    if usage
      puts executor.last_usage_data.inspect
    end
  rescue => e
    puts "#{model_name}: ERROR - #{e.message}"
    puts e.backtrace
  end
end

def main
  options = {}
  OptionParser.new do |opts|
    opts.on("--stream", "Stream the output") do |v|
      options[:stream] = v
    end
    opts.on("--usage", "Show usage") do |v|
      options[:usage] = v
    end
  end.parse!

  models = LLMs::Models.list_model_names(full: true)
  if ARGV[0]
    models = models.select { |name| name.include?(ARGV[0]) }
  end

  models.each do |model_name|
    test_model(model_name, stream: options[:stream], usage: options[:usage])
    puts "-" * 80
  end
end

main
